<!DOCTYPE html>
<html lang="en">
<head>
    <!-- begin Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R62SS642J0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-R62SS642J0');
    </script>
    <!-- end Google tag -->

    <script>
        function showVideo(videoId) {
            document.getElementById('rl_videos').querySelectorAll('div.rl_item').forEach(div => div.style.display = 'none');
            document.getElementById(videoId).style.display = 'block';
            document.getElementById('video_selector').querySelectorAll('button').forEach(btn => btn.classList.remove('active'));
            document.getElementById(videoId + '-btn').classList.add('active');
        }
        document.addEventListener('DOMContentLoaded', function() {
            showVideo('cheetahlow'); // Show the first video by default
        });
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/png" href="/files/eigensafe_favicon.png"></link>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="/style.css">
    <title>EigenSafe: A Spectral Framework for Safety Assessment</title>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <div class="logo">
            <svg width="140" height="140" viewBox="0 0 128 128" fill="none" xmlns="http://www.w3.org/2000/svg">
                <g transform="translate(0, 0), scale(1.0, 0.95)">
                    <path d="M18 20 Q41 28 64 10 Q87 28 110 20 V60 C110 105 64 124 64 124 C64 124 18 105 18 60 V20Z" fill="#FFFFFF" stroke="#c55" stroke-width="12" 
                    stroke-linejoin="round"/>
                </g>
                <g transform="translate(-5, -1)">
                    <path d="M60 12 C 60 12, 72 12, 78 28 L 98 105" stroke="white" stroke-width="24" stroke-linecap="butt"/>
                    <path d="M80 45 L 42 103" stroke="white" stroke-width="24" stroke-linecap="butt"/>
                    <circle cx="60" cy="12" r="12" fill="white"/>
                    <rect x="25.8" y="92.2" width="26" height="18" fill="white"/>
                    <rect x="86" y="92.2" width="26" height="18" fill="white"/>
                    
                    <path d="M60 12 C 60 12, 72 12, 78 28 L 98 105" stroke="#0F172A" stroke-width="16" stroke-linecap="butt" stroke-linejoin="round"/>
                    <path d="M80 45 L 42 103" stroke="#0F172A" stroke-width="16" stroke-linecap="butt" stroke-linejoin="round"/>
                    
                    <rect x="31" y="95.2" width="18" height="12" fill="#0F172A"/>
                    <rect x="90" y="95.2" width="18" height="12" fill="#0F172A"/>
                    <circle cx="60" cy="12" r="8" fill="#0F172A"/>
                </g>
            </svg>
        </div>

        <div class="header-content">
            <h1>EigenSafe: <small>A Spectral Framework for Learning-Based Probabilistic Safety Assessment</small></h1>

            <div class="authors">
                <a href="https://janginkyu.github.io/">Inkyu Jang*<sup>1</sup></a>,
                <a href="https://jonghaepark.github.io/">Jonghae Park*<sup>1</sup></a>,
                Sihyun Cho<sup>1</sup>,
                Chams E. Mballo<sup>2</sup>,
                <a href="https://people.eecs.berkeley.edu/~tomlin/">Claire J. Tomlin<sup>2</sup></a>,
                and H. Jin Kim<sup>1</sup>
            </div>

            <div class="affiliations">
                <sup>1</sup> Seoul National University &nbsp;&nbsp;
                <sup>2</sup> UC Berkeley<br>
                <span style="color: #888; font-size: 0.9em;">* Equal Contribution</span>
            </div>

            <div class="venue"><i>Under Review</i></div>

            <div class="links">
                <!-- <a href="/files/eigensafe-paper.pdf" class="btn"><i class="fas fa-file-pdf"></i> Paper</a> -->
                <a href="https://arxiv.org/abs/2509.17750" class="btn"><i class="ai ai-arxiv"></i> arXiv</a>
                <a href="" class="btn"><i class="fab fa-github"></i> Code</a>
            </div>
        </div>
    </header>

    <section>
        <h2>Summary</h2>
        <ol>
            <li><strong>EigenSafe</strong> is a novel operator-theoretic framework designed to assess the safety of stochastic robotic systems.</li>
            <li>The framework derives a linear operator that governs the evolution of the safety probability over long time horizons.</li>
            <li>The dominant eigenpair of this operator is used as a calibrated safety critic: the dominant eigenvalue serves as a global safety metric for the policy, and the dominant eigenfunction acts as a state-wise safety score.</li>
            <li>The approach is validated in two distinct domains: enforcing safety constraints in reinforcement learning (RL) for continuous control tasks and providing test-time safety filtering for imitation learning (IL) in robotic manipulation.</li>
        </ol>
    </section>

    <section>
        <h2>The Spectral Framework</h2>

        
        <h3>The Dominant Eigenfunction as a Calibrated Safety Critic</h3>

        <p>The evolution of safety probability follows a dynamic programming principle, where the safety probability at the current time step is the expection of the next-step safety probability. We frame this recursive update as a linear operator acting on functions of state-action pairs. <em>The system's asymptotic safety behavior is described by its dominant eigenpair</em>, yielding a metric that is calibrated to the true safety probability.</p>
        
        <div style="background-color: #f8f9fa; padding: 25px; border-radius: 4px; border: 1px solid #eee; margin-bottom: 30px;">
            
            <div style="text-align: center; font-size: 1.2em; padding: 15px 0; overflow-x: auto;">
                $$ \color{#000000}{\mathbb{P}_{\pi}\left[\text{safe until $t$ }\middle| s_0 = x, a_0 = u\right] = {}} \color{#d32f2f}{A_{\pi}^{\color{#000000}{t}}} \color{#000000}{{{1}}_{\text{safe}}(x, u)} \approx c \cdot \color{#2e7d32}{\psi_{\pi}(x, u)} \cdot \color{#1565c0}{\gamma_{\pi}^{\color{#000000}{t}}} $$
            </div>

            <div class="grid-container" style="margin-top: 10px; gap: 40px; display: flex; flex-wrap: nowrap; align-items: flex-start;">
                <div style="border-top: 3px solid #d32f2f; padding-top: 10px; flex: 1; min-width: 0;">
                    <strong style="color: #d32f2f; font-size: 1.1em;">Linear Operator $A_\pi$</strong>
                    <ul style="padding-left: 20px; color: #444; margin-top: 8px;">
                        <li>Governs the evolution of safety probability</li>
                        <li>A positive, non-expansive linear operator</li>
                    </ul>
                </div>

                <div style="border-top: 3px solid #2e7d32; padding-top: 10px; flex: 1; min-width: 0;">
                    <strong style="color: #2e7d32; font-size: 1.1em;">The Dominant Eigenfunction $\psi_{\pi}$</strong>
                    <ul style="padding-left: 20px; color: #444; margin-top: 8px;">
                        <li>Measures the relative safety of each state-action pair $(x, u)$</li>
                        <li>Always nonnegative</li>
                    </ul>
                </div>

                <div style="border-top: 3px solid #1565c0; padding-top: 10px; flex: 1; min-width: 0;">
                    <strong style="color: #1565c0; font-size: 1.1em;">The Dominant Eigenvalue $\gamma_{\pi}$</strong>
                    <ul style="padding-left: 20px; color: #444; margin-top: 8px;">
                        <li>Safety of the overall closed-loop system</li>
                        <li>Always between 0 and 1</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <h3>Dominant Eigenpair Learning</h3>
        <p>To learn the dominant eigenpair, we minimize the following loss functional:</p>

        <div style="text-align: center; font-size: 1.2em; padding: 15px 0; overflow-x: auto;">
            $$ \begin{aligned}
            \mathcal{J}_{\text{eig}}[\gamma, \psi] &= W_\text{eig} \cdot \underbrace{\underset{(x,u,x')\sim \mathcal{D}, u' \sim \pi(\cdot|x')}{\mathbb{E}} \left(1[\text{$x$ safe} \wedge \text{$x'$ safe}] \cdot \psi(x', u') - \gamma \cdot 1[\text{$x$ safe}]\cdot \psi(x,u)\right)^2}_{\text{Eigenpair Loss}} \\
            & \quad \quad {} + W_n \cdot \underbrace{\left(\max_{(x,u,\cdot) \in \mathcal{D}} \psi(x,u) - 1 \right)^2}_{\text{Normalization Loss}}
            \end{aligned} $$
        </div>

        <p>
            The eigenpair loss term enforces the eigenfunction to satisfy the eigenvalue equation, and the normalization loss prevents trivial solutions by constraining the maximum value of $\psi$ to be 1. The learned eigenpair can be used as a <em>calibrated safety critic</em> for policy optimization or test-time safety filtering.
        </p>
    </section>

    <section>
        <h2>Application 1: Safe Reinforcement Learning</h2>
        <p>
            We optimize a policy that maximizes the expected discounted sum of rewards subject to a spectral constraint on the eigenvalue ($\gamma_\pi \geq \gamma_{target}$), ensuring the policy remains <em>safer</em> than a specified threshold. We validate this approach in four (customized) gym environments: <code>CheetahLow</code>, <code>HopperHigh</code>, <code>LunarLanderHard</code>, and <code>AntBall</code>.
        </p>

        <p>
            We compare with three baselines: <br>
            (1) <a href="https://arxiv.org/abs/1801.01290"><em>Vanilla SAC (Haarnoja et al., ICML 2018)</em></a>, where the agent optimizes reward without any safety consideration; <br>
            (2) <a href="https://arxiv.org/abs/2309.13528"><em>RESPO (Ganai et al., NeurIPS 2023)</em></a>, which uses a reachability value function and Lagrange multipliers; and <br>
            (3) <a href="https://arxiv.org/abs/2305.14154"><em>EFPPO (So et al., RSS 2023)</em></a>, which reformulates the safe RL problem into an epigraph form.
            </ol>
        </p>

        <div id="video_selector">
            <button class="btn" id="cheetahlow-btn" onclick="showVideo('cheetahlow')"><code>CheetahLow</code></button>
            <button class="btn" id="hopperhigh-btn" onclick="showVideo('hopperhigh')"><code>HopperHigh</code></button>
            <button class="btn" id="lunarlanderhard-btn" onclick="showVideo('lunarlanderhard')"><code>LunarLanderHard</code></button>
            <button class="btn" id="antball-btn" onclick="showVideo('antball')"><code>AntBall</code></button>
        </div>

        <div id="rl_videos">
            <div class="rl_item" id="cheetahlow">
                <h3><code>CheetahLow</code></h3>
                <p>
                    The <code>CheetahLow</code> environment is a modified version of the standard <a href="https://gymnasium.farama.org/environments/mujoco/half_cheetah/"><code>HalfCheetah</code></a> environment. The agent receives reward based on its forward velocity only, and the safety constraint is defined as maintaining the height of the torso below a certain threshold.
                </p>
                <p>
                    Constraint satisfaction is indicated by the color of the floating ball.
                </p>
                <div class="videos_array">
                    <div class="vline_right">
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/cheetahlow/eigensafe.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption"><strong>EigenSafe<br>(Proposed method)</strong></span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/cheetahlow/sac.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(1) Vanilla SAC<br>(Haarnoja et al., 2018)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/cheetahlow/respo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(2) RESPO<br>(Ganai et al., 2023)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/cheetahlow/efppo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(3) EFPPO<br>(So et al., 2023)</span>
                    </div>
                </div>
            </div>
            <div class="rl_item" id="hopperhigh">
                <h3><code>HopperHigh</code></h3>
                <p>
                    The <code>HopperHigh</code> environment is a modified version of the standard <a href="https://gymnasium.farama.org/environments/mujoco/hopper/"><code>Hopper</code></a> environment. The agent receives reward based on its forward velocity only, and the constraint is to maintain the height of the torso above a certain threshold.
                </p>
                <p>
                    Constraint satisfaction is indicated by the color of the floating ball.
                </p>
                <div class="videos_array">
                    <div class="vline_right">
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/hopperhigh/eigensafe.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption"><strong>EigenSafe<br>(Proposed method)</strong></span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/hopperhigh/sac.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(1) Vanilla SAC<br>(Haarnoja et al., 2018)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/hopperhigh/respo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(2) RESPO<br>(Ganai et al., 2023)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/hopperhigh/efppo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(3) EFPPO<br>(So et al., 2023)</span>
                    </div>
                </div>
            </div>
            <div class="rl_item" id="lunarlanderhard">
                <h3><code>LunarLanderHard</code></h3>
                <p>
                    The <code>LunarLanderHard</code> environment is a more challenging variant of the standard <a href="https://gymnasium.farama.org/environments/box2d/lunar_lander/"><code>LunarLander</code></a> environment, with diversified initial reset states. The reward is given only for successful landing, and the safety constraints are imposed on landing velocity, body orientation, and horizontal position.
                </p>
                <p>
                    Constraint satisfaction is indicated by the color of video frame.
                </p>
                <div class="videos_array">
                    <div class="vline_right">
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/lunarlanderhard/eigensafe.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption"><strong>EigenSafe<br>(Proposed method)</strong></span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/lunarlanderhard/sac.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(1) Vanilla SAC<br>(Haarnoja et al., 2018)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/lunarlanderhard/respo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(2) RESPO<br>(Ganai et al., 2023)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/lunarlanderhard/efppo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(3) EFPPO<br>(So et al., 2023)</span>
                    </div>
                </div>
            </div>
            <div class="rl_item" id="antball">
                <h3><code>AntBall</code></h3>
                <p>
                    The <code>AntBall</code> environment is a modified version of the standard MuJoCo <a href="https://gymnasium.farama.org/environments/mujoco/ant/"><code>Ant</code></a> environment. The agent receives reward based on its forward velocity only, and the safety constraint is to not drop the ball from the plate attached on the torso.
                </p>
                <p>
                    Constraint satisfaction is indicated by the color of the floating ball.
                </p>
                <div class="videos_array">
                    <div class="vline_right">
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/antball/eigensafe.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption"><strong>EigenSafe<br>(Proposed method)</strong></span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/antball/sac.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(1) Vanilla SAC<br>(Haarnoja et al., 2018)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/antball/respo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(2) RESPO<br>(Ganai et al., 2023)</span>
                    </div>
                    <div>
                        <video width="100%" height="auto" nocontrols autoplay loop muted>
                            <source src="/files/antball/efppo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <span class="figure-subcaption">(3) EFPPO<br>(So et al., 2023)</span>
                    </div>
                </div>
            </div>
        </div>

        <p>
            The proposed method consistently achieves higher reward with better constraint satisfaction across all environments, compared to the baselines.
        </p>

        <div>
            <div class="media">
                <img src="/files/rl_comparison_web.svg" style="width: 100%; height: auto;">
            </div>
            <span class="figure-caption">
                <strong>Figure.</strong> Baseline comparison results for safe RL using EigenSafe. The horizontal axis denotes the number of timesteps taken until a safety failure or the agent has reached the maximum episode length, and the vertical axis denotes the total undiscounted episode reward. The error bars denote minimum, average, and maximum values over four random seeds. Gray vertical bars denote the maximum episode length.
            </span>
        </div>

    </section>

    <section>
        <h2>Application 2: Safety-Filtered Imitation Learning</h2>
        <p>
            We apply <strong>EigenSafe</strong> to a stochastic behavior cloning policy on a UR3 robot in a food preparation task. At test time, we sample multiple ($n$) action candidates and select the one with the $k$-th highest eigenfunction value (higher safety critic value).
        </p>

        <div class="grid-container">
            <div>
                <div class="media">
                    <video width="100%" height="auto" nocontrols autoplay loop muted>
                        <source src="/files/il_eigensafe.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <span class="figure-caption">
                    <strong>Video.</strong> Safety-filtered IL using EigenSafe. ($k=10$, $n=50$)
                </span>
            </div>
            <div>
                <div class="media">
                    <video width="100%" height="auto" nocontrols autoplay loop muted>
                        <source src="/files/il_baseline.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <span class="figure-caption">
                    <strong>Video.</strong> Baseline IL (flow policy model) without safety filtering.
                </span>
            </div>
        </div>

        <div class="grid-container">
            <div>
                <div class="media">
                        <img src="/files/il_success_rate.svg" style="width: 600px; height: auto;">
                </div>
                <span class="figure-caption">
                    <strong>Figure.</strong> Success/safety rates in safety-filtered IL ($n=50$). There is a positive correlation between the selecting actions with higher $\psi_\pi$ values and the success/safety rates, except for the $k=1$ case where the action is subject to the risk of being out of distribution.
                </span>
            </div>
        </div>
    </section>


    <section>
        <h2>Abstract</h2>
        <div class="abstract">
            We present <em>EigenSafe</em>, an operator-theoretic framework for safety assessment of learning-enabled stochastic systems. In many robotic applications, the dynamics are inherently stochastic due to factors such as sensing noise and environmental disturbances, and  it is challenging for conventional methods such as Hamilton-Jacobi reachability and control barrier functions to provide a well-calibrated safety critic that is tied to the actual safety probability. We derive a linear operator that governs the dynamic programming principle for safety probability, and find that its dominant eigenpair provides critical safety information for both individual state-action pairs and the overall closed-loop system. The proposed framework learns this dominant eigenpair, which can be used to either inform or constrain policy updates. We demonstrate that the learned eigenpair effectively facilitates safe reinforcement learning. Further, we validate its applicability in enhancing the safety of learned policies from imitation learning through robot manipulation experiments using a UR3 robotic arm in a food preparation task.
        </div>
    </section>

    <section>
        <h2>BibTeX</h2>
        <div class="bibtex">@article{jang2026eigensafe,
  title={EigenSafe: A Spectral Framework for Learning-Based Probabilistic Safety Assessment},
  author={Jang, Inkyu and Park, Jonghae and Cho, Sihyun and Mballo, Chams E and Tomlin, Claire J and Kim, H Jin},
  journal={arXiv preprint arXiv:2509.17750},
  year={2026}
}</div>
    </section>
    <footer>
        EigenSafe Project.
    </footer>

</body>
</html>
